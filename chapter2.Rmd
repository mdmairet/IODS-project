---
title: "Regression and model validation"
author: "Marc Denojean-Mairet"
output: html_document
---



For this analysis, a data frame named **learningAnalysis2014** is created.  The CSV file named "learning2014.csv" is read.  The data frame consist of 7 variables (gender ,Age ,attitude, deep,  stra, surf, Points) and 166 observations.  The data are from a survey of statistics students.  The data include the global attitude of the students toward statistics and their exam points.  deep", "stra" and "surf" are combined variables by taking the mean.  "attitude" was scaled based on Likert scale (1-5) by dividing the "Attitude" column by 10.

More information about the data can be found **here** (https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-meta.txt)
```{r}
learningAnalysis2014 <- read.csv(file = 'data/learning2014.csv')
dim(learningAnalysis2014)
str(learningAnalysis2014)
```
These are plots of all the relationship among the variables.  From the visualization, we see some positive and negative correlations.  An interesting correlation is attitude and points.  As expected, we see a negative correlation with surf and deep.  The most negative correlation is with deep and points.  We also see that there are more female than male students.  However, from the plots, there is no good fit between gender and points and there is no strong correlations.

The summary table gives us more information about the means of the variables.  

```{r}

pairs(learningAnalysis2014[-1], col = "red")

library(ggplot2)
library(GGally)

ggpairs(learningAnalysis2014, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))

summary(learningAnalysis2014)


```

I am using the following 3 variables to explain Points: 'attitude', 'stra', and 'deep'.
```{r}
ggpairs(learningAnalysis2014, lower = list(combo = wrap("facethist", bins = 20)))

my_model <- lm(Points ~ attitude + stra + deep, data = learningAnalysis2014)

summary(my_model)

```
From the above summary table, we see that median for the residual is 0.5474.  This would suggest that it will be difficult to predict points based on attitude, stra, and deep.  However, it is very difficult to predict human behaviors and 0.5 residual could be acceptable in this case.

From the coefficients table, we see that the p-value for deep is high which would mean that deep does not affect much points.  stra and attitude are better to predict points.

Below is a new regression where I have removed deep.

```{r}
my_model2 <- lm(Points ~ attitude + stra, data = learningAnalysis2014)

summary(my_model2)

```
Based on the above summary table, we see that by removing deep, the fit was not improved and actually got worse.

Below are diagnostic plots function: Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage.  The QQ-plot shows a reasonable fit which shows good 'normality'.  The Residuals vs Fitted values plot shows that it is reasonable since it shows randomness. 

```{r}
my_model2 <- lm(Points ~ attitude + stra, data = learningAnalysis2014)

par(mfrow = c(2,2))
plot(my_model2, which = c(1,2,5))
```